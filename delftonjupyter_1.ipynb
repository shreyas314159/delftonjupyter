{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature extraction package import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sensormotion as sm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Numpy and pandas are libraries for working with advanced multidimensional arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as _np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as _pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining simple feature functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imu_feature_simple(filename):\n",
    "    ave, full = imu_features(filename);\n",
    "    return ave "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining full feature functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imu_feature_full(filename):\n",
    "    ave, full = imu_features(filename);\n",
    "    return full"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The major function it returns both simple and full feature functions. The imported sensormotion package is not perfect, so it needs a lot of walk arounds to detect the warnings. The commands are used to create an excel spreadsheet. \n",
    "\n",
    "A filter is used to eliminate the noise and to make the output signals smoother\n",
    "\n",
    "Going through sensor 1, 2 and 3 and to extract the accelerometer values.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imu_features(filename):\n",
    "    import warnings\n",
    "    warnings.filterwarnings('error')\n",
    "    feature_number = 16\n",
    "    feature_index = 0\n",
    "    try:\n",
    "        fileIO = _pd.ExcelFile(filename)\n",
    "        print(filename)\n",
    "            \n",
    "    except:\n",
    "        if not fileIO:\n",
    "            fileIO.close()\n",
    "            \n",
    "    b1, a1 = sm.signal.build_filter(frequency=5,\n",
    "                                  sample_rate=100,\n",
    "                                  filter_type='low',\n",
    "                                  filter_order=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read from the excel sheets the data from the nine rows and extract the time and corresponding acceleration values.\n",
    "\n",
    "After getting these values, extract the vector magnitude of the acceleration \n",
    "\n",
    "From this find, the mean of the vector magnitude of the accleration and its corresponding standard deviation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for sheet_index in range(0, 3):\n",
    "        try:\n",
    "            \n",
    "            df = _pd.read_excel(fileIO, sheet_name = sheet_index, header=None)\n",
    "            \n",
    "            \n",
    "            t = _np.array(df.values[:,0], dtype=_np.float64)\n",
    "            x = _np.array(df.values[:,7], dtype=_np.float64)\n",
    "            y = _np.array(df.values[:,8], dtype=_np.float64)\n",
    "            z = _np.array(df.values[:,9], dtype=_np.float64)\n",
    "            \n",
    "            \n",
    "            temp = _np.multiply(x,x) + _np.multiply(y,y) + _np.multiply(z,z)             \n",
    "            vec_sum = _np.sqrt(temp)            \n",
    "            acc = x\n",
    "            acc = _np.vstack([acc, y])\n",
    "            acc = _np.vstack([acc, z])\n",
    "            acc = _np.vstack([acc, vec_sum])\n",
    "            \n",
    "            amplitute_mean = _np.zeros(4)\n",
    "            amplitute_std = _np.zeros(4)\n",
    "            \n",
    "            for i in range (0,4):\n",
    "                amplitute_mean[i] = _np.mean(acc[i])\n",
    "                amplitute_std[i] = _np.mean(acc[i])\n",
    "            \n",
    "            acc_filterd = []\n",
    "            \n",
    "            for i in range (0,4):\n",
    "                if i == 0:\n",
    "                    #first line we fill in\n",
    "                    acc_filterd = sm.signal.filter_signal(b1, a1, signal=acc[i,:])\n",
    "                else:\n",
    "                    #then we add row by row\n",
    "                    acc_filterd = _np.vstack([acc_filterd, sm.signal.filter_signal(b1, a1, signal=acc[i,:])])\n",
    "                    \n",
    "            cadence =_np.zeros(4)\n",
    "            \n",
    "            step_mean = _np.zeros(4)\n",
    "            \n",
    "            for i in range (0,4):\n",
    "                peak_times, peak_values = sm.peak.find_peaks(time=t, signal=acc_filterd[i],\n",
    "                                                         peak_type='valley',\n",
    "                                                         min_val=0.2, min_dist=1,\n",
    "                                                         plot=False)\n",
    "                step_mean[i], step_sd, step_cov = sm.gait.step_time(peak_times = peak_times)\n",
    "            \n",
    "                cadence[i] = sm.gait.cadence(time=t, peak_times = peak_times, time_units='s')\n",
    "                \n",
    "            feature_index = 0\n",
    "            \n",
    "            for i in range (0,4):\n",
    "                features[sheet_index, feature_index]=amplitute_mean[i]\n",
    "                feature_index =  feature_index + 1\n",
    "            \n",
    "            for i in range (0,4):\n",
    "                features[sheet_index, feature_index]=cadence[i]\n",
    "                feature_index =  feature_index + 1\n",
    "            \n",
    "            for i in range (0,4):\n",
    "                features[sheet_index, feature_index]=step_mean[i]\n",
    "                feature_index =  feature_index + 1\n",
    "                \n",
    "            for i in range (0,4):\n",
    "                features[sheet_index, feature_index]=amplitute_std[i]\n",
    "                feature_index =  feature_index + 1\n",
    "                \n",
    "        except Warning:\n",
    "            pass\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ave_features = _np.array([features[0,3],\\\n",
    "                             features[0,7],\\\n",
    "                             features[0,11],\\\n",
    "                             features[1,3],\\\n",
    "                             features[1,7],\\\n",
    "                             features[1,11],\\\n",
    "                             features[2,3],\\\n",
    "                             features[2,7],\\\n",
    "                             features[2,11]])\n",
    "fileIO.close()\n",
    "    \n",
    "    return ave_features, features;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "working_dir = os.path.dirname(os.path.abspath(__file__))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = []\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Label the data based on 0,1 and 2 commands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for r, d, f in os.walk(data_set_a):\n",
    "    for file in f:\n",
    "        if '.xls' in file:\n",
    "            dataset.append({ \"filename\": data_set_a + file, \"label\": 0 })\n",
    "            \n",
    "for r, d, f in os.walk(data_set_b):\n",
    "    for file in f:\n",
    "        if '.xls' in file:\n",
    "            dataset.append({ \"filename\": data_set_b + file, \"label\": 1 })\n",
    "\n",
    "for r, d, f in os.walk(data_set_c):\n",
    "    for file in f:\n",
    "        if '.xls' in file:\n",
    "            dataset.append({ \"filename\": data_set_c + file, \"label\": 2 })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get all the features from the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data   = []\n",
    "all_labels = []\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "feature extraction from all the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for item in dataset:\n",
    "    #print(item['filename'])\n",
    "    all_data.append(imu_feature_simple(item['filename']))\n",
    "    all_labels.append(item['label'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Change the data type from the list to array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = _np.asarray(all_data)\n",
    "all_labels = _np.asarray(all_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we fill all Nan as the mean of the column\n",
    "Obtain mean of columns as you need, nanmean is just convenient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_mean = _np.nanmean(all_data, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find indices that you need to replace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inds = _np.where(_np.isnan(all_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Place column means in the indices. Align the arrays using take"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data[inds] = _np.take(col_mean, inds[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_np.savez(\"data_1\",all_data=all_data,all_labels=all_labels)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
